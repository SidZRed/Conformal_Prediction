{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K54aU4K9Zsjv",
        "outputId": "31b9435e-551c-4b84-e435-039680dcc3c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ImageNetV2'...\n",
            "remote: Enumerating objects: 1479, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 1479 (delta 2), reused 0 (delta 0), pack-reused 1472 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1479/1479), 122.91 MiB | 22.08 MiB/s, done.\n",
            "Resolving deltas: 100% (1093/1093), done.\n",
            "Updating files: 100% (1375/1375), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/modestyachts/ImageNetV2.git\n",
        "! cd ImageNetV2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install dependencies\n",
        "!pip install git+https://github.com/modestyachts/ImageNetV2_pytorch\n",
        "!pip install tqdm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7QjaVEKb-Qx",
        "outputId": "531abaa9-9d64-4a59-ada2-9889081e6a90"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/modestyachts/ImageNetV2_pytorch\n",
            "  Cloning https://github.com/modestyachts/ImageNetV2_pytorch to /tmp/pip-req-build-q74ue96n\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/modestyachts/ImageNetV2_pytorch /tmp/pip-req-build-q74ue96n\n",
            "  Resolved https://github.com/modestyachts/ImageNetV2_pytorch to commit 14d4456c39fe7f02a665544dd9fc37c1a5f8b635\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: imagenetv2_pytorch\n",
            "  Building wheel for imagenetv2_pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imagenetv2_pytorch: filename=imagenetv2_pytorch-0.1-py3-none-any.whl size=2658 sha256=97d777a87852f8279d1833bb94e9e24f23f16738ef18e43aefa7366b32c32bbe\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-h63993wh/wheels/eb/61/f3/007769f94191be99678049fc34bfce389459b3752fb7f27c78\n",
            "Successfully built imagenetv2_pytorch\n",
            "Installing collected packages: imagenetv2_pytorch\n",
            "Successfully installed imagenetv2_pytorch-0.1\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1y_xn3BZZsjy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import models, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from tqdm import tqdm\n",
        "from torch.nn import functional as F\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import nn, optim\n",
        "from scipy.special import softmax\n",
        "from imagenetv2_pytorch import ImageNetV2Dataset\n",
        "from tqdm import tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_TNs4fUZsjz",
        "outputId": "b8c3d2ae-b8f0-43f6-af37-fa4a508df6c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Step 3: Set device to CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knNtwKXXZsj0",
        "outputId": "bfd36b79-c721-477f-9f57-5358f8dca4c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNeXt101_64X4D_Weights.IMAGENET1K_V1`. You can also use `weights=ResNeXt101_64X4D_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnext101_64x4d-173b62eb.pth\" to /root/.cache/torch/hub/checkpoints/resnext101_64x4d-173b62eb.pth\n",
            "100%|██████████| 319M/319M [00:02<00:00, 144MB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet152-394f9c45.pth\" to /root/.cache/torch/hub/checkpoints/resnet152-394f9c45.pth\n",
            "100%|██████████| 230M/230M [00:01<00:00, 165MB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth\n",
            "100%|██████████| 171M/171M [00:01<00:00, 150MB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:01<00:00, 76.3MB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 78.1MB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_BN_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_BN_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16_bn-6c64b313.pth\" to /root/.cache/torch/hub/checkpoints/vgg16_bn-6c64b313.pth\n",
            "100%|██████████| 528M/528M [00:06<00:00, 82.8MB/s]\n"
          ]
        }
      ],
      "source": [
        "model_constructors = {\n",
        "    \"ResNeXt101\":models.resnext101_64x4d,\n",
        "    \"ResNet152\": models.resnet152,\n",
        "    \"ResNet101\": models.resnet101,\n",
        "    \"ResNet50\": models.resnet50,\n",
        "    \"ResNet18\": models.resnet18,\n",
        "    \"VGG16_BN\": models.vgg16_bn\n",
        "}\n",
        "\n",
        "# Initialize and move models to device\n",
        "model_dict = {}\n",
        "for name, constructor in model_constructors.items():\n",
        "    model = constructor(pretrained=True, progress=True)\n",
        "    model.eval()\n",
        "    model = model.to(device)\n",
        "    model_dict[name] = model\n",
        "\n",
        "# Transformation pipeline\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    ),\n",
        "])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ouNuiFqZsj1"
      },
      "source": [
        " # Load the data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "EHXnsUhnZsj3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f437c6d8-dce7-4689-8d3f-9b6fc1a3979c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset matched-frequency not found on disk, downloading....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.26G/1.26G [00:17<00:00, 70.6MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting....\n"
          ]
        }
      ],
      "source": [
        "batch_size = 128\n",
        "num_calib = 4500\n",
        "num_param = 1000\n",
        "total_size = 10000\n",
        "# Step 6: Load ImageNet-V2 dataset\n",
        "dataset = ImageNetV2Dataset(\"matched-frequency\", transform=transform)\n",
        "calib_set, test_set, param_set = random_split(dataset, [num_calib, total_size - num_param - num_calib, num_param])\n",
        "\n",
        "calib_loader = DataLoader(calib_set, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=True)\n",
        "param_loader = DataLoader(param_set, batch_size=batch_size, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQZRjjBYZsj4"
      },
      "source": [
        " # Function for Conformal Prediction Procedures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "mQ-IV4RJZsj4"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_logits(model, dataloader, device):\n",
        "    model.eval()\n",
        "    logits_list, labels_list = [], []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs = inputs.to(device)\n",
        "            outputs = model(inputs)\n",
        "            logits_list.append(outputs.cpu())\n",
        "            labels_list.append(labels)\n",
        "    return torch.cat(logits_list), torch.cat(labels_list)\n",
        "\n",
        "def temperature_scaling(logits, labels, max_iters=50, lr=0.01, epsilon=1e-4):\n",
        "    T = nn.Parameter(torch.tensor([1.3], requires_grad=True))\n",
        "    optimizer = optim.SGD([T], lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    for i in range(max_iters):\n",
        "        optimizer.zero_grad()\n",
        "        scaled_logits = logits / T\n",
        "        loss = criterion(scaled_logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if abs(loss.item()) < epsilon:\n",
        "            break\n",
        "    return T.detach()\n",
        "\n",
        "def compute_scores(sorted_probs_list, sorted_indices_list, labels,\n",
        "                   lambda_reg=0.1, k_reg=5, randomized=True, allow_zero_sets=True):\n",
        "    scores = []\n",
        "    for i in range(len(labels)):\n",
        "        sorted_probs = sorted_probs_list[i]\n",
        "        sorted_indices = sorted_indices_list[i]\n",
        "        cumsum = np.cumsum(sorted_probs)\n",
        "\n",
        "        penalties = np.zeros_like(sorted_probs)\n",
        "        penalties[k_reg:] += lambda_reg\n",
        "        penalties_cumsum = np.cumsum(penalties)\n",
        "\n",
        "        target = labels[i].item()\n",
        "        rank = np.where(sorted_indices == target)[0][0]\n",
        "\n",
        "        if not randomized:\n",
        "            tau = cumsum[rank] + penalties_cumsum[rank]\n",
        "        else:\n",
        "            U = np.random.rand()\n",
        "            if rank == 0:\n",
        "                tau = U * cumsum[0] + penalties_cumsum[0] if allow_zero_sets else cumsum[0] + penalties_cumsum[0]\n",
        "            else:\n",
        "                tau = U * sorted_probs[rank] + cumsum[rank - 1] + penalties_cumsum[rank]\n",
        "\n",
        "        scores.append(tau)\n",
        "    return np.array(scores)\n",
        "\n",
        "\n",
        "def compute_threshold(scores, alpha):\n",
        "    return np.quantile(scores, 1 - alpha, method=\"higher\")\n",
        "\n",
        "def predict_set(sorted_probs, sorted_indices, tau, lambda_reg=0.1, k_reg=5, randomized=True, allow_zero_sets=True):\n",
        "\n",
        "    cumsum = np.cumsum(sorted_probs)\n",
        "\n",
        "    penalties = np.zeros_like(sorted_probs)\n",
        "    penalties[k_reg:] += lambda_reg\n",
        "    penalties_cumsum = np.cumsum(penalties)\n",
        "\n",
        "    sizes_base = (cumsum + penalties_cumsum <= tau).sum() + 1\n",
        "    sizes_base = min(sizes_base, len(sorted_probs))\n",
        "\n",
        "    if randomized and sizes_base < len(sorted_probs):\n",
        "        V = 1 / sorted_probs[sizes_base - 1] * (\n",
        "            tau - (cumsum[sizes_base - 1] - sorted_probs[sizes_base - 1]) - penalties_cumsum[sizes_base - 1]\n",
        "        )\n",
        "        sizes = sizes_base - int(np.random.rand() >= V)\n",
        "    else:\n",
        "        sizes = sizes_base\n",
        "\n",
        "    if tau == 1.0:\n",
        "        sizes = len(sorted_probs)\n",
        "\n",
        "    if not allow_zero_sets and sizes == 0:\n",
        "        sizes = 1\n",
        "\n",
        "    sizes = max(sizes, 1)\n",
        "    return sorted_indices[:sizes].tolist()\n",
        "\n",
        "\n",
        "def platt_scaling(logits_data, T):\n",
        "    logits_data = logits_data.cpu().numpy()\n",
        "    sorted_probs = []\n",
        "    sorted_indices =[]\n",
        "    for i in range(len(logits_data)):\n",
        "        scaled_logits = logits_data[i] / T.item()\n",
        "        probs = softmax(scaled_logits)\n",
        "        sorted_indices.append(np.argsort(probs)[::-1])\n",
        "        sorted_probs.append(np.sort(probs)[::-1])\n",
        "\n",
        "    return sorted_probs, sorted_indices\n",
        "\n",
        "def optimal_k_reg(sorted_indices_list, labels, alpha):\n",
        "\n",
        "    ranks = []\n",
        "    for i in range(len(labels)):\n",
        "        true_label = labels[i].item()\n",
        "        rank = np.where(sorted_indices_list[i] == true_label)[0][0]\n",
        "        ranks.append(rank)\n",
        "\n",
        "    k_reg = compute_threshold(np.array(ranks), alpha=alpha)\n",
        "    return k_reg\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "lambda_reg = 0.01\n",
        "k_reg = 5\n",
        "randomized = True\n",
        "allow_zero_sets = True\n",
        "allow_optimal_k = True\n",
        "alpha = 0.1\n",
        "methods = ['RAPS', 'APS']\n",
        "\n",
        "models_val = {\n",
        "    'ResNet18': model_dict['ResNet18'],\n",
        "    'ResNet50': model_dict['ResNet50'],\n",
        "    'ResNet101': model_dict['ResNet101'],\n",
        "    'ResNet152': model_dict['ResNet152'],\n",
        "    'ResNeXt101': model_dict['ResNeXt101'],\n",
        "    'VGG16_BN': model_dict['VGG16_BN']\n",
        "}\n",
        "\n",
        "model_results = {}"
      ],
      "metadata": {
        "id": "gsmfLMnb1vkw"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checking for each model"
      ],
      "metadata": {
        "id": "pwUo8e0G10JE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for z in range(5):\n",
        "  dataset = ImageNetV2Dataset(\"matched-frequency\", transform=transform)\n",
        "  calib_set, test_set, param_set = random_split(dataset, [num_calib, total_size - num_param - num_calib, num_param])\n",
        "\n",
        "  calib_loader = DataLoader(calib_set, batch_size=batch_size, shuffle=True)\n",
        "  test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=True)\n",
        "  param_loader = DataLoader(param_set, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "\n",
        "  for model_name, model in models_val.items():\n",
        "      print(f\"\\nRunning model: {model_name}\")\n",
        "\n",
        "\n",
        "\n",
        "      # Get logits\n",
        "      logits_calib, labels_calib = get_logits(model, calib_loader, device)\n",
        "      logits_test, labels_test = get_logits(model, test_loader, device)\n",
        "      param_logits, param_labels = get_logits(model, param_loader, device)\n",
        "\n",
        "      # Scaling\n",
        "      T = temperature_scaling(logits_calib, labels_calib)\n",
        "      sorted_probs_calib, sorted_indices_calib = platt_scaling(logits_calib, T)\n",
        "      sorted_probs_test, sorted_indices_test = platt_scaling(logits_test, T)\n",
        "      sorted_probs_param, sorted_indices_param = platt_scaling(param_logits, T)\n",
        "\n",
        "      results = {}\n",
        "\n",
        "      # RAPS\n",
        "      if allow_optimal_k:\n",
        "          k_reg = optimal_k_reg(sorted_indices_param, param_labels, alpha=alpha)\n",
        "          print(f\"Optimal k_reg for alpha {alpha}: {k_reg}\")\n",
        "\n",
        "      scores = compute_scores(sorted_probs_calib, sorted_indices_calib, labels_calib,\n",
        "                              lambda_reg=lambda_reg, k_reg=k_reg,\n",
        "                              randomized=randomized, allow_zero_sets=allow_zero_sets)\n",
        "      tau = compute_threshold(scores, alpha)\n",
        "\n",
        "      prediction_sets = [\n",
        "          predict_set(sorted_probs_test[i], sorted_indices_test[i], tau,\n",
        "                      lambda_reg=lambda_reg, k_reg=k_reg,\n",
        "                      randomized=randomized, allow_zero_sets=allow_zero_sets)\n",
        "          for i in range(len(sorted_probs_test))\n",
        "      ]\n",
        "      sizes = [len(pset) for pset in prediction_sets]\n",
        "      coverage = np.mean([\n",
        "          labels_test[i].item() in prediction_sets[i] for i in range(len(labels_test))\n",
        "      ])\n",
        "\n",
        "      results['RAPS'] = {\n",
        "          'size': np.mean(sizes),\n",
        "          'coverage': coverage\n",
        "      }\n",
        "\n",
        "      # APS (lambda=0, k_reg=0)\n",
        "      scores_aps = compute_scores(sorted_probs_calib, sorted_indices_calib, labels_calib,\n",
        "                                  lambda_reg=0, k_reg=0,\n",
        "                                  randomized=randomized, allow_zero_sets=allow_zero_sets)\n",
        "      tau_aps = compute_threshold(scores_aps, alpha)\n",
        "\n",
        "      prediction_sets_aps = [\n",
        "          predict_set(sorted_probs_test[i], sorted_indices_test[i], tau_aps,\n",
        "                      lambda_reg=0, k_reg=0,\n",
        "                      randomized=randomized, allow_zero_sets=allow_zero_sets)\n",
        "          for i in range(len(sorted_probs_test))\n",
        "      ]\n",
        "      sizes_aps = [len(pset) for pset in prediction_sets_aps]\n",
        "      coverage_aps = np.mean([\n",
        "          labels_test[i].item() in prediction_sets_aps[i] for i in range(len(labels_test))\n",
        "      ])\n",
        "\n",
        "      results['APS'] = {\n",
        "          'size': np.mean(sizes_aps),\n",
        "          'coverage': coverage_aps\n",
        "      }\n",
        "\n",
        "      # Save results\n",
        "      model_results[model_name] = results\n",
        "\n",
        "  print(\"Iteration\", z)\n",
        "\n",
        "  print(\"\\n=== RAPS vs APS Results ===\")\n",
        "  header = f\"{'Metric':<12} | {'Method':<6} | \" + \" | \".join([f\"{model:<12}\" for model in model_results.keys()])\n",
        "  print(\"-\" * len(header))\n",
        "  print(header)\n",
        "  print(\"-\" * len(header))\n",
        "\n",
        "  # Print Prediction Set Size\n",
        "  print(f\"{'Set Size':<12} | {'APS':<6} | \" + \" | \".join([f\"{model_results[model]['APS']['size']:<12.3f}\" for model in model_results]))\n",
        "  print(f\"{'':<12} | {'RAPS':<6} | \" + \" | \".join([f\"{model_results[model]['RAPS']['size']:<12.3f}\" for model in model_results]))\n",
        "  print(\"-\" * len(header))\n",
        "\n",
        "  # Print Coverage\n",
        "  print(f\"{'Coverage':<12} | {'APS':<6} | \" + \" | \".join([f\"{model_results[model]['APS']['coverage']:<12.3f}\" for model in model_results]))\n",
        "  print(f\"{'':<12} | {'RAPS':<6} | \" + \" | \".join([f\"{model_results[model]['RAPS']['coverage']:<12.3f}\" for model in model_results]))\n",
        "  print(\"-\" * len(header))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uf4Yuw0WrY3q",
        "outputId": "94dccaaa-2c0b-499b-b17b-29c2a4df27a3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running model: ResNet18\n",
            "Optimal k_reg for alpha 0.1: 17\n",
            "\n",
            "Running model: ResNet50\n",
            "Optimal k_reg for alpha 0.1: 10\n",
            "\n",
            "Running model: ResNet101\n",
            "Optimal k_reg for alpha 0.1: 9\n",
            "\n",
            "Running model: ResNet152\n",
            "Optimal k_reg for alpha 0.1: 7\n",
            "\n",
            "Running model: ResNeXt101\n",
            "Optimal k_reg for alpha 0.1: 4\n",
            "\n",
            "Running model: VGG16_BN\n",
            "Optimal k_reg for alpha 0.1: 10\n",
            "Iteration 0\n",
            "\n",
            "=== RAPS vs APS Results ===\n",
            "---------------------------------------------------------------------------------------------------------------\n",
            "Metric       | Method | ResNet18     | ResNet50     | ResNet101    | ResNet152    | ResNeXt101   | VGG16_BN    \n",
            "---------------------------------------------------------------------------------------------------------------\n",
            "Set Size     | APS    | 37.855       | 35.630       | 30.938       | 27.770       | 57.031       | 32.792      \n",
            "             | RAPS   | 16.181       | 10.898       | 9.341        | 8.480        | 6.109        | 11.420      \n",
            "---------------------------------------------------------------------------------------------------------------\n",
            "Coverage     | APS    | 0.912        | 0.926        | 0.919        | 0.926        | 0.920        | 0.922       \n",
            "             | RAPS   | 0.908        | 0.910        | 0.908        | 0.917        | 0.914        | 0.911       \n",
            "---------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "Running model: ResNet18\n",
            "Optimal k_reg for alpha 0.1: 15\n",
            "\n",
            "Running model: ResNet50\n",
            "Optimal k_reg for alpha 0.1: 9\n",
            "\n",
            "Running model: ResNet101\n",
            "Optimal k_reg for alpha 0.1: 7\n",
            "\n",
            "Running model: ResNet152\n",
            "Optimal k_reg for alpha 0.1: 6\n",
            "\n",
            "Running model: ResNeXt101\n",
            "Optimal k_reg for alpha 0.1: 4\n",
            "\n",
            "Running model: VGG16_BN\n",
            "Optimal k_reg for alpha 0.1: 11\n",
            "Iteration 1\n",
            "\n",
            "=== RAPS vs APS Results ===\n",
            "---------------------------------------------------------------------------------------------------------------\n",
            "Metric       | Method | ResNet18     | ResNet50     | ResNet101    | ResNet152    | ResNeXt101   | VGG16_BN    \n",
            "---------------------------------------------------------------------------------------------------------------\n",
            "Set Size     | APS    | 42.721       | 36.130       | 33.435       | 29.513       | 54.303       | 33.163      \n",
            "             | RAPS   | 16.305       | 10.804       | 9.233        | 8.297        | 6.037        | 11.602      \n",
            "---------------------------------------------------------------------------------------------------------------\n",
            "Coverage     | APS    | 0.922        | 0.922        | 0.923        | 0.924        | 0.912        | 0.921       \n",
            "             | RAPS   | 0.908        | 0.909        | 0.912        | 0.911        | 0.909        | 0.907       \n",
            "---------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "Running model: ResNet18\n",
            "Optimal k_reg for alpha 0.1: 14\n",
            "\n",
            "Running model: ResNet50\n",
            "Optimal k_reg for alpha 0.1: 9\n",
            "\n",
            "Running model: ResNet101\n",
            "Optimal k_reg for alpha 0.1: 8\n",
            "\n",
            "Running model: ResNet152\n",
            "Optimal k_reg for alpha 0.1: 6\n",
            "\n",
            "Running model: ResNeXt101\n",
            "Optimal k_reg for alpha 0.1: 4\n",
            "\n",
            "Running model: VGG16_BN\n",
            "Optimal k_reg for alpha 0.1: 9\n",
            "Iteration 2\n",
            "\n",
            "=== RAPS vs APS Results ===\n",
            "---------------------------------------------------------------------------------------------------------------\n",
            "Metric       | Method | ResNet18     | ResNet50     | ResNet101    | ResNet152    | ResNeXt101   | VGG16_BN    \n",
            "---------------------------------------------------------------------------------------------------------------\n",
            "Set Size     | APS    | 40.748       | 32.800       | 29.772       | 27.037       | 56.229       | 32.848      \n",
            "             | RAPS   | 15.535       | 10.658       | 8.954        | 8.074        | 5.973        | 11.159      \n",
            "---------------------------------------------------------------------------------------------------------------\n",
            "Coverage     | APS    | 0.917        | 0.921        | 0.917        | 0.925        | 0.919        | 0.925       \n",
            "             | RAPS   | 0.909        | 0.914        | 0.908        | 0.913        | 0.908        | 0.909       \n",
            "---------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "Running model: ResNet18\n",
            "Optimal k_reg for alpha 0.1: 15\n",
            "\n",
            "Running model: ResNet50\n",
            "Optimal k_reg for alpha 0.1: 11\n",
            "\n",
            "Running model: ResNet101\n",
            "Optimal k_reg for alpha 0.1: 7\n",
            "\n",
            "Running model: ResNet152\n",
            "Optimal k_reg for alpha 0.1: 6\n",
            "\n",
            "Running model: ResNeXt101\n",
            "Optimal k_reg for alpha 0.1: 4\n",
            "\n",
            "Running model: VGG16_BN\n",
            "Optimal k_reg for alpha 0.1: 11\n",
            "Iteration 3\n",
            "\n",
            "=== RAPS vs APS Results ===\n",
            "---------------------------------------------------------------------------------------------------------------\n",
            "Metric       | Method | ResNet18     | ResNet50     | ResNet101    | ResNet152    | ResNeXt101   | VGG16_BN    \n",
            "---------------------------------------------------------------------------------------------------------------\n",
            "Set Size     | APS    | 39.149       | 36.673       | 31.318       | 28.216       | 52.176       | 31.124      \n",
            "             | RAPS   | 15.596       | 11.305       | 8.818        | 8.312        | 5.865        | 11.353      \n",
            "---------------------------------------------------------------------------------------------------------------\n",
            "Coverage     | APS    | 0.917        | 0.927        | 0.918        | 0.925        | 0.912        | 0.922       \n",
            "             | RAPS   | 0.909        | 0.914        | 0.910        | 0.913        | 0.905        | 0.905       \n",
            "---------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "Running model: ResNet18\n",
            "Optimal k_reg for alpha 0.1: 18\n",
            "\n",
            "Running model: ResNet50\n",
            "Optimal k_reg for alpha 0.1: 11\n",
            "\n",
            "Running model: ResNet101\n",
            "Optimal k_reg for alpha 0.1: 8\n",
            "\n",
            "Running model: ResNet152\n",
            "Optimal k_reg for alpha 0.1: 6\n",
            "\n",
            "Running model: ResNeXt101\n",
            "Optimal k_reg for alpha 0.1: 4\n",
            "\n",
            "Running model: VGG16_BN\n",
            "Optimal k_reg for alpha 0.1: 10\n",
            "Iteration 4\n",
            "\n",
            "=== RAPS vs APS Results ===\n",
            "---------------------------------------------------------------------------------------------------------------\n",
            "Metric       | Method | ResNet18     | ResNet50     | ResNet101    | ResNet152    | ResNeXt101   | VGG16_BN    \n",
            "---------------------------------------------------------------------------------------------------------------\n",
            "Set Size     | APS    | 36.476       | 32.266       | 30.533       | 27.225       | 58.567       | 30.935      \n",
            "             | RAPS   | 15.670       | 10.822       | 9.006        | 8.008        | 5.890        | 11.548      \n",
            "---------------------------------------------------------------------------------------------------------------\n",
            "Coverage     | APS    | 0.912        | 0.922        | 0.920        | 0.926        | 0.924        | 0.918       \n",
            "             | RAPS   | 0.901        | 0.911        | 0.912        | 0.913        | 0.908        | 0.910       \n",
            "---------------------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ljHxuOuYG36D"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}