# Conformal_Prediction

Repository for project on **Conformal Prediction**

Conformal Prediction is a powerful statistical framework for uncertainty quantification in machine learning. It produces *prediction sets* instead of point estimates, offering formal guarantees on coverage with minimal assumptions. These guarantees hold regardless of the underlying model's accuracy or the data distribution, making the approach model-agnostic and distribution-free‚Äîeven in finite-sample settings.

This repository contains experiments and implementations aimed at evaluating and extending conformal prediction methods in both classification and regression contexts. We investigate different score functions, model backbones, and calibration strategies. Special emphasis is given to RAPS (Risk Adaptive Prediction Sets), adaptive set formation, and empirical analysis of marginal coverage under varying calibration set sizes.

---

## üìÅ Repository Structure

